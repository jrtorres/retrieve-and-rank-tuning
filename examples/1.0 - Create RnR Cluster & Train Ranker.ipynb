{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 - Create RnR Cluster (& Train Ranker)\n",
    "\n",
    "Simple example which will:\n",
    "\n",
    "1. Create a RnR Cluster\n",
    "2. Create a new document collection\n",
    "3. Upload documents into that collection\n",
    "4. Train a ranker that can be used with the collection\n",
    "5. Query the collection with and without a ranker\n",
    "\n",
    "**Note:** To better understand the impact of querying with and without a ranker, see the next example on evaluation.\n",
    "\n",
    "### The Data \n",
    "We make use of the InsuranceLibV2 data: https://github.com/shuzi/insuranceQA.  At a high level, the InsuranceLibV2 is a _Question Answering_ data set provided for benchmarking and research, it consists of question and answers collected from the [Insurance Library](http://www.insurancelibrary.com/).\n",
    "\n",
    " - There are **27,413 possible answers** in this extract and each looks something like: \n",
    "\n",
    "> Coverage follows the car. Example 1: if you were given a car (loaned) and the car has no insurance, you can buy insurance on the car and your insurance will be primary. Another option, someone helped you to buy a car. For example your credit score isn't good enough to finance, so a friend of yours signed under your loan as a primary payor. You can get insurance under your name and even list your friend on the policy as a loss payee. In this case, we always suggest you get a loan gap coverage: the difference between the car's actual cash value and the amount still owned on it. Example 2: the car you are loaned has insurance. You can buy a policy under your name, list the car on that policy and in case of the accident, your policy will become a secondary or excess. Once the limits of the primary car insurance are exhausted, your coverage would kick in and hopefully pay for the rest. I specifically used the word hopefully, because each accident is unique and it's hard to interpret the coverage without the actual claim scenario. And even with a given claim scenario, sometimes there are 2 possible outcomes of a claim.\n",
    "\n",
    " - In addition, a **16,899 questions** have been labelled with the answer ids that are relevant to the question. We use a subset of those questions (specifically the 2,000 dev subset) as input to train a ranker. The questions look like this:\n",
    " \n",
    "> Does auto insurance go down when you turn 21?\n",
    "\n",
    "*Note:* Ensure credentials have been updated in config/config.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary scripts and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config from /stuff/workspace/rnr-debugging-scripts/config/config.ini\n",
      "Using data from /stuff/workspace/rnr-debugging-scripts/resources/insurance_lib_v2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from os import path, getcwd\n",
    "import json\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "sys.path.extend([path.abspath(path.join(getcwd(), path.pardir))])\n",
    "\n",
    "from rnr_debug_helpers.utils.rnr_wrappers import RetrieveAndRankProxy, RankerProxy\n",
    "from rnr_debug_helpers.utils.io_helpers import load_config, smart_file_open, RankerRelevanceFileQueryStream\n",
    "from rnr_debug_helpers.generate_rnr_feature_file import generate_rnr_features\n",
    "\n",
    "config_file_path = path.abspath(path.join(getcwd(), path.pardir, 'config', 'config.ini'))\n",
    "print('Using config from {}'.format(config_file_path))\n",
    "\n",
    "config = load_config(config_file_path=config_file_path)\n",
    "\n",
    "insurance_lib_data_dir = path.abspath(path.join(getcwd(), path.pardir, 'resources', 'insurance_lib_v2'))\n",
    "print('Using data from {}'.format(insurance_lib_data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a RnR Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-16 19:29:28,213 INFO BluemixServiceProxy - Creating a new cluster with name Test Cluster and size 2\n",
      "2017-05-16 19:29:28,216 INFO BluemixServiceProxy - Submitting request to create a cluster\n",
      "{\n",
      "    \"cluster_name\": \"Test Cluster\",\n",
      "    \"cluster_size\": \"2\",\n",
      "    \"solr_cluster_id\": \"sc40bbecbd_362a_4388_b61b_e3a90578d3b3\",\n",
      "    \"solr_cluster_status\": \"NOT_AVAILABLE\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "# Either re-use an existing solr cluster id by over riding the below, or leave as None to create a new cluster\n",
    "cluster_id = None\n",
    "\n",
    "# If you choose to leave it as None, it'll use these details to request a new cluster\n",
    "cluster_name = 'Test Cluster'\n",
    "cluster_size = '2'\n",
    "\n",
    "bluemix_wrapper = RetrieveAndRankProxy(solr_cluster_id=cluster_id, \n",
    "                                       cluster_name=cluster_name, \n",
    "                                       cluster_size=cluster_size, \n",
    "                                       config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create a Solr collection\n",
    "Here we create a Solr document collection in the previously created cluster and upload the InsuranceLibV2 documents (i.e. answers) to the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-16 19:29:29,030 INFO BluemixServiceProxy - Waiting for cluster <<sc40bbecbd_362a_4388_b61b_e3a90578d3b3>> to become available\n",
      "2017-05-16 19:33:30,807 INFO BluemixServiceProxy - Solr cluster sc40bbecbd_362a_4388_b61b_e3a90578d3b3 is available for use\n",
      "{\n",
      "    \"cluster_name\": \"Test Cluster\",\n",
      "    \"cluster_size\": \"2\",\n",
      "    \"solr_cluster_id\": \"sc40bbecbd_362a_4388_b61b_e3a90578d3b3\",\n",
      "    \"solr_cluster_status\": \"READY\"\n",
      "}2017-05-16 19:33:31,214 INFO BluemixServiceProxy - Uploading solr configurations\n",
      "{\n",
      "    \"message\": \"WRRCSR026: Successfully uploaded named config [TestConfig] for Solr cluster [sc40bbecbd_362a_4388_b61b_e3a90578d3b3].\",\n",
      "    \"statusCode\": 200\n",
      "}2017-05-16 19:33:33,191 INFO BluemixServiceProxy - Creating a collection: TestCollection\n",
      "{\n",
      "    \"responseHeader\": {\n",
      "        \"QTime\": 12864,\n",
      "        \"status\": 0\n",
      "    },\n",
      "    \"success\": {\n",
      "        \"10.176.142.184:5911_solr\": {\n",
      "            \"core\": \"TestCollection_shard1_replica1\",\n",
      "            \"responseHeader\": {\n",
      "                \"QTime\": 4011,\n",
      "                \"status\": 0\n",
      "            }\n",
      "        },\n",
      "        \"10.176.39.45:6035_solr\": {\n",
      "            \"core\": \"TestCollection_shard1_replica2\",\n",
      "            \"responseHeader\": {\n",
      "                \"QTime\": 4579,\n",
      "                \"status\": 0\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}2017-05-16 19:33:47,062 INFO BluemixServiceProxy - Collection: <<TestCollection>> in cluster: <<sc40bbecbd_362a_4388_b61b_e3a90578d3b3>> (with config: <<TestConfig>>) setup with 0 documents\n"
     ]
    }
   ],
   "source": [
    "collection_id = 'TestCollection'\n",
    "config_id = 'TestConfig'\n",
    "zipped_solr_config = path.join(insurance_lib_data_dir, 'config.zip')\n",
    "\n",
    "bluemix_wrapper.setup_cluster_and_collection(collection_id=collection_id, config_id=config_id,\n",
    "                                             config_zip=zipped_solr_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Upload documents\n",
    " \n",
    " The InsuranceLibV2 had to be pre-processed and formatted into the Solr format for adding documents.  \n",
    "\n",
    "__TODO:__ show the scripts for how to do this conversion to solr format from the raw data provided at https://github.com/shuzi/insuranceQA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading from: /stuff/workspace/rnr-debugging-scripts/resources/insurance_lib_v2/document_corpus.solr.xml\n",
      "Uploaded 27413 documents to the collection\n"
     ]
    }
   ],
   "source": [
    "documents = path.join(insurance_lib_data_dir, 'document_corpus.solr.xml')\n",
    "\n",
    "print('Uploading from: %s' % documents)\n",
    "bluemix_wrapper.upload_documents_to_collection(collection_id=collection_id, corpus_file=documents,\n",
    "                                               content_type='application/xml')\n",
    "\n",
    "print('Uploaded %d documents to the collection' % \n",
    "      bluemix_wrapper.get_num_docs_in_collection(collection_id=collection_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Ranker\n",
    "Since we already have the annotated queries with the document ids that are relevant in this case, we can use that to train a ranker.  \n",
    "__TODO:__ show the scripts for how to do this conversion to the relevance file format from the raw data provided at https://github.com/shuzi/insuranceQA.\n",
    "\n",
    "#### Generate a feature file\n",
    "The ranker trains on top of a [features](https://stackoverflow.com/questions/37314360/how-to-interpret-featurevector-and-score-in-ibm-retrieverank-results/43357905#43357905) derived between the questions and the answers; so we need to use the service to generate such a feature file first.  During this feature file generation process, we need to decide on the [`num_rows` parameter](http://stackoverflow.com/questions/39353793/watson-retrieve-rank-difference-in-answer-when-asked-using-web-ui-versus-an/39354106#39354106).  Will go into this in more detail in a separate example, for now, we set this to `50`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving file to: /tmp/tmpiw275r2e/ranker_feature_file.csv\n",
      "2017-05-16 22:40:55,172 INFO BluemixServiceProxy - Using previously created solr cluster id: sc40bbecbd_362a_4388_b61b_e3a90578d3b3\n",
      "{\n",
      "    \"cluster_name\": \"Test Cluster\",\n",
      "    \"cluster_size\": \"2\",\n",
      "    \"solr_cluster_id\": \"sc40bbecbd_362a_4388_b61b_e3a90578d3b3\",\n",
      "    \"solr_cluster_status\": \"READY\"\n",
      "}2017-05-16 22:41:38,307 INFO generate_rnr_feature_file.py - Processed 100 queries from input file\n",
      "2017-05-16 22:42:21,257 INFO generate_rnr_feature_file.py - Processed 200 queries from input file\n",
      "2017-05-16 22:43:04,129 INFO generate_rnr_feature_file.py - Processed 300 queries from input file\n",
      "2017-05-16 22:43:46,875 INFO generate_rnr_feature_file.py - Processed 400 queries from input file\n",
      "2017-05-16 22:44:29,704 INFO generate_rnr_feature_file.py - Processed 500 queries from input file\n",
      "2017-05-16 22:45:11,905 INFO generate_rnr_feature_file.py - Processed 600 queries from input file\n",
      "2017-05-16 22:45:54,345 INFO generate_rnr_feature_file.py - Processed 700 queries from input file\n",
      "2017-05-16 22:46:36,680 INFO generate_rnr_feature_file.py - Processed 800 queries from input file\n",
      "2017-05-16 22:47:19,090 INFO generate_rnr_feature_file.py - Processed 900 queries from input file\n",
      "2017-05-16 22:48:01,135 INFO generate_rnr_feature_file.py - Processed 1000 queries from input file\n",
      "2017-05-16 22:48:43,585 INFO generate_rnr_feature_file.py - Processed 1100 queries from input file\n",
      "2017-05-16 22:49:26,230 INFO generate_rnr_feature_file.py - Processed 1200 queries from input file\n",
      "2017-05-16 22:50:08,852 INFO generate_rnr_feature_file.py - Processed 1300 queries from input file\n",
      "2017-05-16 22:50:51,227 INFO generate_rnr_feature_file.py - Processed 1400 queries from input file\n",
      "2017-05-16 22:51:33,910 INFO generate_rnr_feature_file.py - Processed 1500 queries from input file\n",
      "2017-05-16 22:52:18,686 INFO generate_rnr_feature_file.py - Processed 1600 queries from input file\n",
      "2017-05-16 22:53:05,727 INFO generate_rnr_feature_file.py - Processed 1700 queries from input file\n",
      "2017-05-16 22:53:48,312 INFO generate_rnr_feature_file.py - Processed 1800 queries from input file\n",
      "2017-05-16 22:54:30,721 INFO generate_rnr_feature_file.py - Processed 1900 queries from input file\n",
      "2017-05-16 22:55:13,072 INFO generate_rnr_feature_file.py - Processed 2000 queries from input file\n",
      "2017-05-16 22:55:13,074 ERROR LabelledQueryStream - Unable to parse values from line 2001 of file <_io.TextIOWrapper name='/stuff/workspace/rnr-debugging-scripts/resources/insurance_lib_v2/validation_gt_relevance_file.csv' mode='r' encoding='utf-8'> due to error: \n",
      "2017-05-16 22:55:13,076 INFO generate_rnr_feature_file.py - Finished processing 2000 queries from input file\n",
      "{\n",
      "    \"avg_num_correct_answers_per_query_in_gt_file\": 1.677,\n",
      "    \"avg_num_correct_answers_per_query_in_rnr_results_default\": 0.3455,\n",
      "    \"avg_num_search_results_retrieved_per_query\": 50.0,\n",
      "    \"num_correct_in_gt_file\": 3354,\n",
      "    \"num_correct_in_search_result\": 691,\n",
      "    \"num_occurrences_of_label_1\": 3354,\n",
      "    \"num_queries\": 2000,\n",
      "    \"num_queries_where_at_least_correct_answer_didnt_appear_in_rnr\": 1578,\n",
      "    \"num_queries_with_atleast_one_search_result\": 2000,\n",
      "    \"num_search_results_retrieved\": 100000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "collection_id = 'TestCollection'\n",
    "cluster_id = 'sc40bbecbd_362a_4388_b61b_e3a90578d3b3'\n",
    "temporary_output_dir = mkdtemp()\n",
    "\n",
    "feature_file = path.join(temporary_output_dir, 'ranker_feature_file.csv')\n",
    "print('Saving file to: %s' % feature_file)\n",
    "num_rows = 50\n",
    "with smart_file_open(path.join(insurance_lib_data_dir, 'validation_gt_relevance_file.csv')) as infile:\n",
    "    query_stream = RankerRelevanceFileQueryStream(infile)\n",
    "    with smart_file_open(feature_file, mode='w') as outfile:\n",
    "        stats = generate_rnr_features(collection_id=collection_id, cluster_id=cluster_id, num_rows=num_rows,\n",
    "                                      in_query_stream=query_stream, outfile=outfile, config=config)\n",
    "        print(json.dumps(stats, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Train with the Feature File\n",
    "\n",
    "**WARNING:** Each RnR account gives you 8 rankers to be active at any given time, since I experiment a lot, I have a convenience flag to delete rankers in case the quota is full. You obviously want to switch this flag off if you have rankers you don't want deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-16 22:55:13,109 INFO BluemixServiceProxy - Submitting request to create a new ranker trained with file /tmp/tmpiw275r2e/ranker_feature_file.csv\n",
      "2017-05-16 22:55:13,112 INFO BluemixServiceProxy - Generating a version of the feature file without answer id (which is what ranker training expects\n",
      "2017-05-16 22:55:13,513 INFO BluemixServiceProxy - Done generating file: /tmp/tmpiw275r2e/ranker_feature_file.no_aid.csv\n",
      "2017-05-16 22:55:13,514 INFO BluemixServiceProxy - Checking file size before making train call for /tmp/tmpiw275r2e/ranker_feature_file.no_aid.csv\n",
      "2017-05-16 22:55:13,514 INFO BluemixServiceProxy - File size looks ok: 10265794 bytes\n",
      "2017-05-16 22:55:21,790 INFO BluemixServiceProxy - Training request submitted successfully for ranker id:<<81aacex30-rank-5568>>\n",
      "2017-05-16 22:55:21,793 INFO BluemixServiceProxy - Checking/Waiting for training to complete for ranker 81aacex30-rank-5568\n",
      "2017-05-16 22:59:24,429 INFO BluemixServiceProxy - Finished waiting for ranker <<81aacex30-rank-5568>> to train: Available\n"
     ]
    }
   ],
   "source": [
    "ranker_api_wrapper = RankerProxy(config=config)\n",
    "ranker_name = 'TestRanker'\n",
    "ranker_id = ranker_api_wrapper.train_ranker(train_file_location=feature_file, train_file_has_answer_id=True,\n",
    "                                            is_enabled_make_space=True, ranker_name=ranker_name)\n",
    "ranker_api_wrapper.wait_for_training_to_complete(ranker_id=ranker_id)\n",
    "\n",
    "# Delete local feature file since ranker training is done\n",
    "from shutil import rmtree\n",
    "rmtree(temporary_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the cluster with questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-17 00:23:41,885 INFO BluemixServiceProxy - Using previously created solr cluster id: sc40bbecbd_362a_4388_b61b_e3a90578d3b3\n",
      "{\n",
      "    \"cluster_name\": \"Test Cluster\",\n",
      "    \"cluster_size\": \"2\",\n",
      "    \"solr_cluster_id\": \"sc40bbecbd_362a_4388_b61b_e3a90578d3b3\",\n",
      "    \"solr_cluster_status\": \"READY\"\n",
      "}Querying with: can i add my brother to my health insurance \n",
      "\n",
      "Without Ranker\n",
      "Result 1:\n",
      "\tid: 2374\n",
      "\tbody:talk to your insurance professional , but in my experience , yes , you would each need to obtain you...\n",
      "Result 2:\n",
      "\tid: 6149\n",
      "\tbody:is life insurance necessary for a single person ? i will answer based on my reasons for having life ...\n",
      "Result 3:\n",
      "\tid: 4495\n",
      "\tbody:right , right , right , right . in this case ... take the new plan . if this was outside of work , c...\n",
      "\n",
      "With Ranker\n",
      "Result 1:\n",
      "\tid: 7105\n",
      "\tbody:typically , a parent would add your brother to to a health insurance policy that they purchase and y...\n",
      "Result 2:\n",
      "\tid: 22273\n",
      "\tbody:your brother can only add you to his health insurance if he claims you as a dependent on his taxes ....\n",
      "Result 3:\n",
      "\tid: 8658\n",
      "\tbody:did you know that this type of policy was first created by dr. marius bernard , in 1983 in south afr...\n"
     ]
    }
   ],
   "source": [
    "query_string = 'can i add my brother to my health insurance '\n",
    "\n",
    "def print_results(response, num_to_print=3):\n",
    "    results = json.loads(response)['response']['docs']\n",
    "    for i, doc in enumerate(results[0:num_to_print]):        \n",
    "        print('Result {}:\\n\\tid: {}\\n\\tbody:{}...'.format(i+1,doc['id'], \" \".join(doc['body'])[0:100]))\n",
    "    \n",
    "bluemix_wrapper = RetrieveAndRankProxy(solr_cluster_id=\"sc40bbecbd_362a_4388_b61b_e3a90578d3b3\",\n",
    "                                       config=config)\n",
    "\n",
    "print('Querying with: {}'.format(query_string))\n",
    "\n",
    "# without the ranker\n",
    "pysolr_client = bluemix_wrapper.get_pysolr_client(collection_id=collection_id)\n",
    "response = pysolr_client._send_request(\"GET\", path=\"/fcselect?q=%s&wt=json&rows=3\" % query_string)\n",
    "\n",
    "print(\"\\nWithout Ranker\")\n",
    "print_results(response)\n",
    "\n",
    "# with ranker\n",
    "pysolr_client = bluemix_wrapper.get_pysolr_client(collection_id=collection_id)\n",
    "response = pysolr_client._send_request(\"GET\", path=\"/fcselect?q=%s&wt=json&rows=%d&ranker_id=%s\" %\n",
    "                                                  (query_string, num_rows, ranker_id))\n",
    "print(\"\\nWith Ranker\")\n",
    "print_results(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
